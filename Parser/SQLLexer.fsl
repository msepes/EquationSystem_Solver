{   
module SqlLexer
open System   
open SQLParser  
open FSharp.Text.Lexing
 
let keywords =   
    [   
        "SELECT", SELECT;   
        "FROM", FROM;   
        "WHERE", WHERE;   
        "ORDER", ORDER;   
        "BY", BY;   
        "JOIN", JOIN;   
        "INNER", INNER;   
        "LEFT", LEFT;   
        "RIGHT", RIGHT;   
        "ASC", ASC;   
        "DESC", DESC;   
        "AND", AND;   
        "OR", OR;   
        "ON", ON;   
    ] |> Map.ofList   
 
let ops =   
    [   
        "=",    EQ;   
        "<",    LT;   
        "<=",   LE;   
        ">",    GT;   
        ">=",   GE;   
        "IS",   IS;   
        "IS NOT",   ISNOT;   

    ] |> Map.ofList   

let lexeme = LexBuffer<_>.LexemeString
}   


let char        = ['a'-'z' 'A'-'Z']   
let digit       = ['0'-'9']   
let null = "Null" | "null" | "NULL"
let int         = '-'?digit+   
let float       = '-'?digit+ '.' digit+   
let identifier  = char(char|digit|['-' '_' '.'])*   
let whitespace  = [' ' '\t']   
let newline     = "\n\r" | '\n' | '\r'  
let operator    = ">" | ">=" | "<" | "<=" | "=" | "IS" | "IS NOT"
 
rule tokenize = parse   
| whitespace    { tokenize lexbuf }   
| newline       { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf; }   
| int           { INT(Int32.Parse(lexeme lexbuf)) }   
| float         { FLOAT(Double.Parse(lexeme lexbuf)) }   
| null          { NULL }
| operator      { ops.[lexeme lexbuf] }   
| identifier    { match keywords.TryFind(lexeme lexbuf) with   
                  | Some(token) -> token   
                  | None -> ID(lexeme lexbuf) }   
| ','           { COMMA }   
| eof           { EOF }
| _ { raise (Exception (sprintf "SyntaxError: Unexpected char: '%s' Line: %d Column: %d" (lexeme lexbuf) (lexbuf.StartPos.Line+1) lexbuf.StartPos.Column)) }
